---
title: "Data Exploration for DS Jobs"
author: "Gary Nguyen"
date: "2021-05-29"
---

## 1. Load Libraries

```{r library}
library(tidyverse)
library(here)
library(lubridate)
library(glue)
library(sf)
library(tigris)
library(ggthemes)
library(reshape2)
```

## 2 Load Data

```{r load_data}
df <- read_csv('../data/data_science_jobs.csv')
df <- df %>% 
  dplyr::rename(index = X1)
```

## 3. Analyses by Companies

## 4. Analyses by Time

```{r index_by_year}
p <- df %>% 
  filter(YEAR > 2007) %>% 
  group_by(YEAR) %>% 
  summarize(AVG_ML_INDEX = mean(ML_INDEX),
            AVG_NLP_INDEX = mean(NLP_INDEX),
            AVG_CV_INDEX = mean(CV_INDEX)) %>% 
  melt(id.vars = 'YEAR') %>% 
  ggplot() +
  geom_line(aes(x = YEAR, y = value, group = variable, color = variable)) +
  theme_hc() +
  xlab('Year') +
  ylab('Index') +
  ggtitle('Index Values by Year')

ggsave(file.path(here::here(), 'figures/index_values_by_year.png'), p, dpi = 300)
```

## 5. Analyses by Job Types

## 6. Geographical Analysis

```{r jobs_by_states}
jobs_by_states <- df %>% 
  distinct(index, FIPS_STATE)
```

```{r load_geom_data}
terr_to_ignore <- c(
  'Alaska',
  'American Samoa',
  'Commonwealth of the Northern Mariana Islands',
  'Hawaii',
  'Puerto Rico',
  'United States Virgin Islands',
  'Guam'
)

add_leading_zeros <- function(x) {
  case_when(
    str_length(x == 1) ~ paste0('0', x),
    TRUE ~ x
    )
}

sf_data <- readRDS('../data/gadm36_USA_1_sf.rds')
```

```{r num_ds_job_per_state}
p <- df %>% 
  group_by(STATE) %>% tally() %>% ungroup() %>% 
  right_join(sf_data, by = c('STATE' = 'NAME_1')) %>% 
  filter(!STATE %in% terr_to_ignore) %>% 
  ggplot(aes(geometry = geometry)) +
  geom_sf(aes(fill = n)) +
  scale_fill_gradient(high = '#e34a33', low = '#fee8c8', guide = 'colorbar') +
  ggtitle('Number of Job Postings Per State')

print(p)
ggsave('../figures/num_ds_job_per_state.png', p)
```

```{r num_ds_job_per_state_amazon}
p <- df %>% 
  filter(EMPLOYER == 'Amazon') %>% 
  group_by(STATE) %>% tally() %>% ungroup() %>% 
  right_join(sf_data, by = c('STATE' = 'NAME_1')) %>% 
  filter(!STATE %in% terr_to_ignore) %>% 
  ggplot(aes(geometry = geometry)) +
  geom_sf(aes(fill = n)) +
  scale_fill_gradient(high = '#e34a33', low = '#fee8c8', guide = 'colorbar') +
  ggtitle('Number of Job Postings Per State')

print(p)
ggsave(file.path(here::here(), 'data/num_ds_job_per_state_amazon.png'), p)
```

```{r num_ds_job_per_state_ge}
p <- df %>% 
  filter(EMPLOYER == 'General Electric Company') %>% 
  group_by(STATE) %>% tally() %>% ungroup() %>% 
  right_join(sf_data, by = c('STATE' = 'NAME_1')) %>% 
  filter(!STATE %in% terr_to_ignore) %>% 
  ggplot(aes(geometry = geometry)) +
  geom_sf(aes(fill = n)) +
  scale_fill_gradient(high = '#e34a33', low = '#fee8c8', guide = 'colorbar') +
  ggtitle('Number of Job Postings Per State')

print(p)
ggsave(file.path(here::here(), 'data/num_ds_job_per_state_ge.png'), p)
```

```{r num_ds_job_per_state_jpm}
p <- df %>% 
  filter(EMPLOYER == 'JP Morgan Chase Company') %>% 
  group_by(STATE) %>% tally() %>% ungroup() %>% 
  right_join(sf_data, by = c('STATE' = 'NAME_1')) %>% 
  filter(!STATE %in% terr_to_ignore) %>% 
  ggplot(aes(geometry = geometry)) +
  geom_sf(aes(fill = n)) +
  scale_fill_gradient(high = '#e34a33', low = '#fee8c8', guide = 'colorbar') +
  ggtitle('Number of Job Postings Per State')

print(p)
ggsave(file.path(here::here(), 'data/num_ds_job_per_state_jpm.png'), p)
```

## 7. Text Analyses

## 8. Skills Analysis

```{r top_20_skills}
all_skills <- df %>% 
  select(contains('SKILL')) %>% 
  select(-NUM_SKILL) %>% 
  unlist() %>% 
  unname() 

top_20_skills <- table(all_skills) %>% 
  as_tibble() %>% 
  dplyr::rename(SKILL = all_skills,
                FREQ = n) %>% 
  arrange(desc(FREQ)) %>% 
  slice(1:20)
```

```{r top_20_skills_plot}
p <- top_20_skills %>% 
  ggplot(aes(x = reorder(SKILL, FREQ), y = FREQ, label = FREQ)) +
  geom_bar(stat='identity', fill = 'tomato') + coord_flip() +
  geom_text(hjust = -0.5, size = 3) + 
  scale_y_continuous(labels = scales::comma) +
  xlab('Skill') +
  ylab('Occurences') +
  ggtitle('Top 20 Skills in Data Science Jobs') +
  theme_hc() +
  ylim(0, 11000)

ggsave(file.path(here::here(), 'figures/top_20_skills.png'), p, dpi = 300)
```

```{r df_top_95_ml}
qt_95_ml <- quantile(df$ML_INDEX, seq(0, 1, 0.05)) %>% 
  .[20] %>% unname()

df_top_95_ml <- df %>% 
  filter(ML_INDEX > qt_95_ml)

all_skills_ml <- df_top_95_ml %>% 
  select(contains('SKILL')) %>% 
  select(-NUM_SKILL) %>% 
  unlist() %>% 
  unname() 

top_20_skills_ml <- table(all_skills_ml) %>% 
  as_tibble() %>% 
  dplyr::rename(SKILL = all_skills_ml,
                FREQ = n) %>% 
  arrange(desc(FREQ)) %>% 
  slice(1:20)

p <- top_20_skills_ml %>% 
  ggplot(aes(x = reorder(SKILL, FREQ), y = FREQ, label = FREQ)) +
  geom_bar(stat='identity', fill = 'tomato') + coord_flip() +
  geom_text(hjust = -0.5, size = 3) + 
  scale_y_continuous(labels = scales::comma) +
  xlab('Skill') +
  ylab('Occurences') +
  ggtitle('Top 20 Skills in Data Science Jobs \n(Top 95% ML Jobs)') +
  theme_hc() +
  ylim(0, 600)

ggsave(file.path(here::here(), 'figures/top_20_skills_ml.png'), p, dpi = 300)
```

```{r df_top_95_cv}
qt_95_cv <- quantile(df$CV_INDEX, seq(0, 1, 0.05)) %>% 
  .[20] %>% unname()

df_top_95_cv <- df %>% 
  filter(CV_INDEX > qt_95_cv)

all_skills_cv <- df_top_95_cv %>% 
  select(contains('SKILL')) %>% 
  select(-NUM_SKILL) %>% 
  unlist() %>% 
  unname() 

top_20_skills_cv <- table(all_skills_cv) %>% 
  as_tibble() %>% 
  dplyr::rename(SKILL = all_skills_cv,
                FREQ = n) %>% 
  arrange(desc(FREQ)) %>% 
  slice(1:20)

p <- top_20_skills_cv %>% 
  ggplot(aes(x = reorder(SKILL, FREQ), y = FREQ, label = FREQ)) +
  geom_bar(stat='identity', fill = 'tomato') + coord_flip() +
  geom_text(hjust = -0.5, size = 3) + 
  scale_y_continuous(labels = scales::comma) +
  xlab('Skill') +
  ylab('Occurences') +
  ggtitle('Top 20 Skills in Data Science Jobs \n(Top 95% CV Jobs)') +
  theme_hc() +
  ylim(0, 600)

ggsave(file.path(here::here(), 'figures/top_20_skills_cv.png'), p, dpi = 300)
```

```{r df_top_95_nlp}
qt_95_nlp <- quantile(df$NLP_INDEX, seq(0, 1, 0.05)) %>% 
  .[20] %>% unname()

df_top_95_nlp <- df %>% 
  filter(NLP_INDEX > qt_95_nlp)

all_skills_nlp <- df_top_95_nlp %>% 
  select(contains('SKILL')) %>% 
  select(-NUM_SKILL) %>% 
  unlist() %>% 
  unname() 

top_20_skills_nlp <- table(all_skills_nlp) %>% 
  as_tibble() %>% 
  dplyr::rename(SKILL = all_skills_nlp,
                FREQ = n) %>% 
  arrange(desc(FREQ)) %>% 
  slice(1:20)

p <- top_20_skills_nlp %>% 
  ggplot(aes(x = reorder(SKILL, FREQ), y = FREQ, label = FREQ)) +
  geom_bar(stat='identity', fill = 'tomato') + coord_flip() +
  geom_text(hjust = -0.5, size = 3) + 
  scale_y_continuous(labels = scales::comma) +
  xlab('Skill') +
  ylab('Occurences') +
  ggtitle('Top 20 Skills in Data Science Jobs \n(Top 95% NLP Jobs)') +
  theme_hc() +
  ylim(0, 550)

ggsave(file.path(here::here(), 'figures/top_20_skills_nlp.png'), p, dpi = 300)
```

## 9. Sector Analysis

```{r ds_jobs_sector}
p <- df %>% 
  group_by(SECTOR_NAME) %>% 
  tally() %>% ungroup() %>% 
  arrange(desc(n)) %>% 
  ggplot(aes(x = reorder(SECTOR_NAME, n), y = n, fill = n, label = n)) +
  geom_bar(stat = 'identity') +
  coord_flip() +
  scale_fill_viridis_c() +
  xlab('Sector') + 
  ylab('Number of Jobs') +
  ggtitle('Sectors of Data Science Jobs') +
  geom_text(hjust = -0.25, size = 3) +
  ylim(0, 9000)

ggsave(file.path(here::here(), 'figures/ds_job_sectors.png'), p, dpi = 300)
```








